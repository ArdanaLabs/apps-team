\documentclass[12pt]{article}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{hyperref}

\title{Parallel transaction processing for decentralized exchange smart contracts on the Cardano blockchain}
\author{Morgan Thomas / Ardana Labs / Platonic.Systems}

\begin{document}

\maketitle

\begin{center}
	\textbf{For internal distribution only.}
\end{center}

\section{Context}

Cardano smart contracts support, at most, one transaction per block\footnote{
  The Cardano blockchain is built on an EUTXO system.
  This means that each smart contract's state is represented by a UTXO.
  Any transaction which updates the contract's state consumes this UTXO and produces a
  new UTXO. Under these constraints, transactions that update the contract must be executed sequentially.
  In other words, the next transaction in the queue must wait for the previous
  transaction to conclude so it can consume the resulting UTXO.}.
This means that the system can only execute, at most, three transactions per
minute, which is not enough to support applications such as a decentralized
exchange (DEX).

To solve this problem, one can start by launching a Cardano DEX on top of
\href{https://orbisprotocol.com/}{Orbis}, a second layer solution based on
Zero-Knowledge Rollups.
The Orbis project is designed to increase Cardano's transaction throughput to thousands of
transactions per second.
However, the Orbis project is limited in its sequential transaction throughput.
In this paper, we will investigate a possible workaround for this limitation.
Though the focus is on the decentralized exchange application, some lessons may
be applicable to other projects as well.

The limitation of one transaction per block per contract instance suggests that using more than one contract instance will allow us to increase throughput.
This possibility behooves us to ask how we can structure a contract composed of multiple
instances in a way that produces a unified result.

I will start by presenting a simplified DEX contract model, which we can use to study the issue at a high level.

The contract has three endpoints: one to execute a trade, one to add funds, and one to remove funds. There are $n$ distinct assets $a_1,...,a_n$ in the liquidity pool, along with a liquidity pool token asset that liquidity providers receive in exchange for depositing funds. The DEX contains a set $S$ of contract states and a function $\texttt{balances} : S \to \mathbb{R}^n$,
which extracts the current asset balances from the states. There is also an invariant function $I : S \to \mathbb{R}$,
such that for all states $s \in S$ which are attainable, the invariant equation $I(s) = 0$ holds true.
In other words, for initial state $s_0$, $I(s_0) = 0$ holds true. And for any $s$ where there exists a transaction sending $s$ to $s'$, if $I(s) = 0$ then $I(s') = 0$

The pricing of trades is such that if the balance of asset $a_i$ decreases relative to the other assets in the pool, then a trade for $a_i$ becomes more
expensive relative to a trade for another asset, and vice versa; if the balance of $a_i$ becomes relatively higher, then a trade for $a_i$ becomes relatively cheaper. The pricing of trades is determined by solving the invariant equation.

When the user adds liquidity to this system, they are rewarded liquidity pool tokens based on how close their deposit brings the proportion of assets in the pool to its ideal level. The closer their deposit matches this ideal, the more liquidity pool tokens they receive. The number of liquidity tokens generated is determined by solving the invariant equation.

When the user removes liquidity, they do not get to choose which assets they receive. Instead, they automatically receive a share of each asset held in the pool proportional to the amount of liquidity tokens they are redeeming, divided by the total amount of liquidity tokens in existence. 

\section{Strategy}

Our strategy for increasing transaction throughput is to create many copies of the same DEX contract and assemble them into a single abstraction using off-chain software. From the end-users' perspective, these copies appear to be a single pool, while, in fact, they are independent pools that do not communicate or coordinate with each other. However, they share a single liquidity token asset class.

Cross-pool arbitrage ensures that the liquidity tokens can be priced consistently. If liquidity tokens are worth substantially more in one pool than in another, then arbitrageurs
will add liquidity to the pool where the tokens are worth less and redeem them in
a pool where they are worth more. We need to check that this type of arbitrage will, in fact, cause the liquidity token prices among the different pools to converge.

Cross-pool arbitrage also ensures that assets can be priced consistently across pools.
If the prices in one pool differ substantially from another pool's, then arbitrageurs
will resort to instant arbitrage swaps, which should cause the prices among the different pools to converge.

Each pool will have a limit on its size (i.e., amount of liquidity). The limit can vary from pool to pool. This feature ensures that the pool sizes cannot get too far out of
balance. If some pools have very little liquidity and some pools have too much liquidity,
this prevents swaps from being done in parallelâ€”even though the set of
pools, in theory, can support as many transactions per block as there are pools. 

At any given time, there is a limit on how much liquidity can exist within the system. The limit equals the sum of the pools' size limits. If the amount of liquidity in the system comes close to reaching this limit, then it ensures that nearly every pool contains its maximum amount of liquidity. This means that the pools are in balance, with almost none having too much or too little liquidity, which fulfills the goal of supporting parallel transactions.

There are many different ways to implement this feature.

We have options for how we can set the pools' size limits. The limit can be the same for each pool, or, likely more useful, the limits can vary across pools. Within this variation, we would have a small number of large pools to support large swaps and a larger number of small pools to support small swaps.

There are also options for when and how we can increase the system's liquidity limit. We can say that when the liquidity limit is reached, we automatically add more pools or increase the existing pools' limits so that users can add more liquidity. In this case, we say that human intervention is required to increase the liquidity limit. If we say that human intervention is required, then that intervention can be voted on by the decentralized governance protocol, or it can be done in a centralized fashion by the exchange operators.

These options for increasing the system's liquidity limit have different consequences. If human intervention is not required to increase the limit, then liquidity can increase indefinitely and users can always add liquidity. If we do require human intervention, then it sets a lower bound (relative to the trading volume) on liquidity utilization and, thus, on liquidity provider profit.
This could be a desirable property, but the consequences are hard to anticipate because, as far as we know, it hasn't been tried before in other DEX projects. It could also have legal ramifications, which could differ depending on whether it is implemented by the decentralized governance protocol or by the exchange operators.

There are also options for how to assemble the set of independent pools into an abstraction of a single pool. The basic concept here is that when a user wishes to perform a transaction,
the system will select a suitable pool with sufficient funds to be a counterparty to the desired swap, or one that has sufficient funds to redeem a certain amount of
liquidity tokens, or one that is sufficiently below its liquidity limit to receive the user's liquidity.
It may be that a desired transaction is so large that it cannot be executed against any single pool, in which case the transaction will be split into pieces, and those pieces will be executed against multiple pools to achieve the result the user is seeking.

Various pool selection algorithms are available, and we should provide algorithms
that increase economic efficiency. A swap, for example, will execute at a different price in different pools, so we should select a pool which provides one of the better prices available. We should not necessarily select a pool which provides the *best* price, because that could lead to resource contention if that pool is (as will often the be the case) the best one for multiple users' transactions. So, for example, we can order the pools in the ordering relation ``provides a better price for this swap than,''
and then select one in the best $x\%$ of all pools. 

A pool selection algorithm that provides economic efficiency for the user also increases the efficiency of the market. For example, the best pool to execute a swap against is also the pool that most needs the transaction to regulate its prices and put it back into balance with the other pools. In other words, efficient pool selection for swaps does the same price-regulating work that cross-pool arbitrage does. To select these pools, we can order them by the relation ``is a better pool to do this transaction on than.'' Similar principles will apply to other transactions as well: namely, adding and removing liquidity. 

We provide a means by which users can ignore the reality of many pools
and experience all of them as one. This includes a mechanism which
automatically selects, behind the scenes, a pool or pools to perform their
transaction against. It also includes mechanisms that produce unified prices
for assets and liquidity tokens. However, users can, if they wish, choose which pool they perform a transaction against. They may review the prices for liquidity tokens and assets among the individual pools and choose specific ones for their transaction. Arbitrage
trading is just one example of an activity that may benefit from doing this. We
cannot reasonably prevent users from interacting with the individual pools in
any manner they choose, so we need to design the system in a way where
their actions are not likely to disrupt the proper functioning of the system. We can achieve this by making it where users' interaction with individual pools, in pursuit of their economic interests, will tend to increase the market's efficiency. The opportunities opened up by interacting with individual pools are in the nature of
cross-pool arbitrage and are hypothesized to increase market efficiency by promoting consistency in prices across the different pools. Arbitrage
opportunities exploit price differences between the pools and have the tendency
(or so we hypothesize) to flatten out those differences, causing arbitrage opportunities to disappear. The expected end result is a market where the price differences between the
various pools are small enough that arbitraging them away is not profitable after accounting for transaction costs.

\end{document}
